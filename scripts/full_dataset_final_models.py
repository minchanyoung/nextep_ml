import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import LabelEncoder
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score, accuracy_score, classification_report
from sklearn.ensemble import VotingRegressor, VotingClassifier
import xgboost as xgb
import catboost as cb
import lightgbm as lgb
import joblib
import warnings
import time
warnings.filterwarnings('ignore')

plt.rcParams['font.family'] = 'Malgun Gothic'
plt.rcParams['axes.unicode_minus'] = False

print("=== ì „ì²´ ë°ì´í„°ì…‹ ê¸°ë°˜ ìµœì¢… ëª¨ë¸ êµ¬ì¶• ===")

class FullDatasetModelSystem:
    """ì „ì²´ ë°ì´í„°ì…‹ì„ ì‚¬ìš©í•œ ìµœì¢… ëª¨ë¸ ì‹œìŠ¤í…œ"""
    
    def __init__(self):
        self.individual_models = {}
        self.ensemble_models = {}
        self.results = {}
        
    def load_and_prepare_data(self):
        """ì „ì²´ ë°ì´í„°ì…‹ ë¡œë“œ ë° ì „ì²˜ë¦¬"""
        print("ì „ì²´ ë°ì´í„°ì…‹ ë¡œë“œ ì¤‘...")
        
        df = pd.read_csv('processed_data/dataset_with_unified_occupations.csv')
        
        # ì˜ˆì¸¡ ê°€ëŠ¥í•œ ì¼€ì´ìŠ¤ë§Œ ì„ ë³„
        df_sorted = df.sort_values(['pid', 'year']).reset_index(drop=True)
        
        # ë‹¤ìŒ ì—°ë„ íƒ€ê²Ÿ ìƒì„±
        df_sorted['next_year'] = df_sorted.groupby('pid')['year'].shift(-1)
        df_sorted['next_wage'] = df_sorted.groupby('pid')['p_wage'].shift(-1)
        df_sorted['next_satisfaction'] = df_sorted.groupby('pid')['p4321'].shift(-1)
        
        # ì—°ì†ëœ ì—°ë„ë§Œ í•„í„°ë§
        consecutive_mask = (df_sorted['next_year'] == df_sorted['year'] + 1)
        df_consecutive = df_sorted[consecutive_mask].copy()
        
        # íƒ€ê²Ÿì´ ëª¨ë‘ ìˆëŠ” ì¼€ì´ìŠ¤ë§Œ ì„ ë³„ ë° ë§Œì¡±ë„ -1 ì œê±°
        valid_mask = (~df_consecutive['next_wage'].isna()) & (~df_consecutive['next_satisfaction'].isna()) & (df_consecutive['next_satisfaction'] > 0)
        df_final = df_consecutive[valid_mask].copy()
        
        print(f"ì „ì²´ ìœ íš¨ ë°ì´í„°: {df_final.shape[0]}ê°œ")
        
        # íŠ¹ì„± ì„ íƒ
        exclude_cols = ['pid', 'year', 'next_year', 'next_wage', 'next_satisfaction', 'p_wage', 'p4321']
        feature_cols = [col for col in df_final.columns if col not in exclude_cols]
        
        # ë²”ì£¼í˜• ë³€ìˆ˜ ì¸ì½”ë”©
        print("ë²”ì£¼í˜• ë³€ìˆ˜ ì¸ì½”ë”© ì¤‘...")
        for col in df_final[feature_cols].select_dtypes(include=['object']).columns:
            le = LabelEncoder()
            df_final[col] = le.fit_transform(df_final[col].astype(str))
        
        # ê²°ì¸¡ê°’ ì²˜ë¦¬
        print("ê²°ì¸¡ê°’ ì²˜ë¦¬ ì¤‘...")
        df_final[feature_cols] = df_final[feature_cols].fillna(df_final[feature_cols].median())
        
        # ì‹œê°„ ê¸°ë°˜ ë¶„í• 
        train_mask = df_final['year'] <= 2020
        test_mask = df_final['year'] >= 2021
        
        self.X_train = df_final[train_mask][feature_cols]
        self.X_test = df_final[test_mask][feature_cols]
        self.y_wage_train = df_final[train_mask]['next_wage']
        self.y_wage_test = df_final[test_mask]['next_wage']
        # ë§Œì¡±ë„ë¥¼ 0ë¶€í„° ì‹œì‘í•˜ë„ë¡ ë³€í™˜ (1-5 â†’ 0-4)
        self.y_sat_train = (df_final[train_mask]['next_satisfaction'] - 1).astype(int)
        self.y_sat_test = (df_final[test_mask]['next_satisfaction'] - 1).astype(int)
        
        self.feature_names = feature_cols
        
        print(f"í›ˆë ¨ ë°ì´í„°: {self.X_train.shape[0]:,}ê°œ")
        print(f"í…ŒìŠ¤íŠ¸ ë°ì´í„°: {self.X_test.shape[0]:,}ê°œ")
        print(f"íŠ¹ì„± ê°œìˆ˜: {len(self.feature_names)}ê°œ")
    
    def train_individual_models(self):
        """ê°œë³„ ëª¨ë¸ í›ˆë ¨ - ì „ì²´ ë°ì´í„°ì…‹ ì‚¬ìš©"""
        print("\nê°œë³„ ëª¨ë¸ í›ˆë ¨ ì¤‘... (ì „ì²´ ë°ì´í„°ì…‹ ì‚¬ìš©)")
        
        # ì„ê¸ˆ ì˜ˆì¸¡ ëª¨ë¸ë“¤
        print("  ì„ê¸ˆ ì˜ˆì¸¡ ëª¨ë¸ë“¤...")
        
        # CatBoost (ìµœê³  ì„±ëŠ¥ ëª¨ë¸)
        print("    CatBoost í›ˆë ¨ ì¤‘...")
        self.individual_models['catboost_wage'] = cb.CatBoostRegressor(
            iterations=2000,  # ë” ë§ì€ ë°˜ë³µ
            learning_rate=0.05,  # ë” ë‚®ì€ í•™ìŠµë¥ 
            depth=8,  # ë” ê¹Šì€ ëª¨ë¸
            l2_leaf_reg=3,
            random_seed=42,
            verbose=100  # ì§„í–‰ìƒí™© í‘œì‹œ
        )
        self.individual_models['catboost_wage'].fit(self.X_train, self.y_wage_train)
        
        # XGBoost
        print("    XGBoost í›ˆë ¨ ì¤‘...")
        self.individual_models['xgb_wage'] = xgb.XGBRegressor(
            n_estimators=2000,
            learning_rate=0.05,
            max_depth=8,
            subsample=0.9,
            colsample_bytree=0.9,
            random_state=42,
            verbosity=1
        )
        self.individual_models['xgb_wage'].fit(self.X_train, self.y_wage_train)
        
        # LightGBM
        print("    LightGBM í›ˆë ¨ ì¤‘...")
        self.individual_models['lgb_wage'] = lgb.LGBMRegressor(
            n_estimators=2000,
            learning_rate=0.05,
            max_depth=8,
            subsample=0.9,
            colsample_bytree=0.9,
            random_state=42,
            verbose=100
        )
        self.individual_models['lgb_wage'].fit(self.X_train, self.y_wage_train)
        
        # ë§Œì¡±ë„ ì˜ˆì¸¡ ëª¨ë¸ë“¤
        print("  ë§Œì¡±ë„ ì˜ˆì¸¡ ëª¨ë¸ë“¤...")
        
        # XGBoost (ìµœê³  ì„±ëŠ¥ ëª¨ë¸)
        print("    XGBoost ë¶„ë¥˜ ëª¨ë¸ í›ˆë ¨ ì¤‘...")
        self.individual_models['xgb_satisfaction'] = xgb.XGBClassifier(
            n_estimators=2000,
            learning_rate=0.05,
            max_depth=8,
            subsample=0.9,
            colsample_bytree=0.9,
            random_state=42,
            verbosity=1
        )
        self.individual_models['xgb_satisfaction'].fit(self.X_train, self.y_sat_train)
        
        # CatBoost
        print("    CatBoost ë¶„ë¥˜ ëª¨ë¸ í›ˆë ¨ ì¤‘...")
        self.individual_models['catboost_satisfaction'] = cb.CatBoostClassifier(
            iterations=2000,
            learning_rate=0.05,
            depth=8,
            random_seed=42,
            verbose=100
        )
        self.individual_models['catboost_satisfaction'].fit(self.X_train, self.y_sat_train)
        
        # LightGBM
        print("    LightGBM ë¶„ë¥˜ ëª¨ë¸ í›ˆë ¨ ì¤‘...")
        self.individual_models['lgb_satisfaction'] = lgb.LGBMClassifier(
            n_estimators=2000,
            learning_rate=0.05,
            max_depth=8,
            subsample=0.9,
            colsample_bytree=0.9,
            random_state=42,
            verbose=100
        )
        self.individual_models['lgb_satisfaction'].fit(self.X_train, self.y_sat_train)
        
        print("  ê°œë³„ ëª¨ë¸ í›ˆë ¨ ì™„ë£Œ!")
    
    def create_ensemble_models(self):
        """ì•™ìƒë¸” ëª¨ë¸ ìƒì„±"""
        print("\nì•™ìƒë¸” ëª¨ë¸ ìƒì„±...")
        
        # ì„ê¸ˆ ì˜ˆì¸¡ ì•™ìƒë¸”
        wage_estimators = [
            ('catboost', self.individual_models['catboost_wage']),
            ('xgboost', self.individual_models['xgb_wage']),
            ('lightgbm', self.individual_models['lgb_wage'])
        ]
        
        self.ensemble_models['wage_ensemble'] = VotingRegressor(
            estimators=wage_estimators,
            n_jobs=-1
        )
        print("  ì„ê¸ˆ ì•™ìƒë¸” í›ˆë ¨ ì¤‘...")
        self.ensemble_models['wage_ensemble'].fit(self.X_train, self.y_wage_train)
        
        # ë§Œì¡±ë„ ì˜ˆì¸¡ ì•™ìƒë¸”
        satisfaction_estimators = [
            ('xgboost', self.individual_models['xgb_satisfaction']),
            ('catboost', self.individual_models['catboost_satisfaction']),
            ('lightgbm', self.individual_models['lgb_satisfaction'])
        ]
        
        self.ensemble_models['satisfaction_ensemble'] = VotingClassifier(
            estimators=satisfaction_estimators,
            voting='soft',
            n_jobs=-1
        )
        print("  ë§Œì¡±ë„ ì•™ìƒë¸” í›ˆë ¨ ì¤‘...")
        self.ensemble_models['satisfaction_ensemble'].fit(self.X_train, self.y_sat_train)
        
        print("  ì•™ìƒë¸” ëª¨ë¸ ìƒì„± ì™„ë£Œ!")
    
    def evaluate_all_models(self):
        """ëª¨ë“  ëª¨ë¸ ì„±ëŠ¥ í‰ê°€ - MAE í¬í•¨"""
        print("\nëª¨ë¸ ì„±ëŠ¥ í‰ê°€ (RMSE, MAE, RÂ², ì •í™•ë„)...")
        
        self.results = {'individual': {}, 'ensemble': {}}
        
        # ê°œë³„ ëª¨ë¸ í‰ê°€
        print("  ê°œë³„ ëª¨ë¸ ì„±ëŠ¥:")
        
        # ì„ê¸ˆ ì˜ˆì¸¡ ê°œë³„ ëª¨ë¸
        wage_models = ['catboost_wage', 'xgb_wage', 'lgb_wage']
        for model_name in wage_models:
            model = self.individual_models[model_name]
            y_pred_train = model.predict(self.X_train)
            y_pred_test = model.predict(self.X_test)
            
            train_rmse = np.sqrt(mean_squared_error(self.y_wage_train, y_pred_train))
            test_rmse = np.sqrt(mean_squared_error(self.y_wage_test, y_pred_test))
            train_mae = mean_absolute_error(self.y_wage_train, y_pred_train)
            test_mae = mean_absolute_error(self.y_wage_test, y_pred_test)
            train_r2 = r2_score(self.y_wage_train, y_pred_train)
            test_r2 = r2_score(self.y_wage_test, y_pred_test)
            
            self.results['individual'][model_name] = {
                'train_rmse': train_rmse, 'test_rmse': test_rmse,
                'train_mae': train_mae, 'test_mae': test_mae,
                'train_r2': train_r2, 'test_r2': test_r2
            }
            
            print(f"    {model_name}: RMSE={test_rmse:.2f}, MAE={test_mae:.2f}, RÂ²={test_r2:.4f}")
        
        # ë§Œì¡±ë„ ì˜ˆì¸¡ ê°œë³„ ëª¨ë¸
        sat_models = ['xgb_satisfaction', 'catboost_satisfaction', 'lgb_satisfaction']
        for model_name in sat_models:
            model = self.individual_models[model_name]
            y_pred_train = model.predict(self.X_train)
            y_pred_test = model.predict(self.X_test)
            
            train_acc = accuracy_score(self.y_sat_train, y_pred_train)
            test_acc = accuracy_score(self.y_sat_test, y_pred_test)
            
            self.results['individual'][model_name] = {
                'train_accuracy': train_acc,
                'test_accuracy': test_acc
            }
            
            print(f"    {model_name}: ì •í™•ë„={test_acc:.4f}")
        
        # ì•™ìƒë¸” ëª¨ë¸ í‰ê°€
        print("\n  ì•™ìƒë¸” ëª¨ë¸ ì„±ëŠ¥:")
        
        # ì„ê¸ˆ ì•™ìƒë¸”
        y_pred_train = self.ensemble_models['wage_ensemble'].predict(self.X_train)
        y_pred_test = self.ensemble_models['wage_ensemble'].predict(self.X_test)
        
        train_rmse = np.sqrt(mean_squared_error(self.y_wage_train, y_pred_train))
        test_rmse = np.sqrt(mean_squared_error(self.y_wage_test, y_pred_test))
        train_mae = mean_absolute_error(self.y_wage_train, y_pred_train)
        test_mae = mean_absolute_error(self.y_wage_test, y_pred_test)
        train_r2 = r2_score(self.y_wage_train, y_pred_train)
        test_r2 = r2_score(self.y_wage_test, y_pred_test)
        
        self.results['ensemble']['wage'] = {
            'train_rmse': train_rmse, 'test_rmse': test_rmse,
            'train_mae': train_mae, 'test_mae': test_mae,
            'train_r2': train_r2, 'test_r2': test_r2
        }
        
        print(f"    ì„ê¸ˆ ì•™ìƒë¸”: RMSE={test_rmse:.2f}, MAE={test_mae:.2f}, RÂ²={test_r2:.4f}")
        
        # ë§Œì¡±ë„ ì•™ìƒë¸”
        y_pred_train = self.ensemble_models['satisfaction_ensemble'].predict(self.X_train)
        y_pred_test = self.ensemble_models['satisfaction_ensemble'].predict(self.X_test)
        
        train_acc = accuracy_score(self.y_sat_train, y_pred_train)
        test_acc = accuracy_score(self.y_sat_test, y_pred_test)
        
        self.results['ensemble']['satisfaction'] = {
            'train_accuracy': train_acc,
            'test_accuracy': test_acc
        }
        
        print(f"    ë§Œì¡±ë„ ì•™ìƒë¸”: ì •í™•ë„={test_acc:.4f}")
    
    def create_comprehensive_visualization(self):
        """ì¢…í•© ì„±ëŠ¥ ì‹œê°í™” - MAE í¬í•¨"""
        print("\nì¢…í•© ì„±ëŠ¥ ë¹„êµ ì‹œê°í™” ìƒì„±...")
        
        fig, axes = plt.subplots(2, 3, figsize=(20, 12))
        
        # 1. ì„ê¸ˆ ì˜ˆì¸¡ RMSE ë¹„êµ
        wage_models = ['CatBoost', 'XGBoost', 'LightGBM', 'Ensemble']
        wage_rmse = [
            self.results['individual']['catboost_wage']['test_rmse'],
            self.results['individual']['xgb_wage']['test_rmse'],
            self.results['individual']['lgb_wage']['test_rmse'],
            self.results['ensemble']['wage']['test_rmse']
        ]
        
        colors = ['lightblue', 'lightgreen', 'lightcoral', 'orange']
        bars = axes[0, 0].bar(wage_models, wage_rmse, color=colors)
        axes[0, 0].set_title('ì„ê¸ˆ ì˜ˆì¸¡ ëª¨ë¸ RMSE ë¹„êµ', fontweight='bold', fontsize=12)
        axes[0, 0].set_ylabel('RMSE (ë§Œì›)')
        
        for bar, value in zip(bars, wage_rmse):
            height = bar.get_height()
            axes[0, 0].text(bar.get_x() + bar.get_width()/2., height + 1,
                           f'{value:.1f}', ha='center', va='bottom')
        
        # 2. ì„ê¸ˆ ì˜ˆì¸¡ MAE ë¹„êµ
        wage_mae = [
            self.results['individual']['catboost_wage']['test_mae'],
            self.results['individual']['xgb_wage']['test_mae'],
            self.results['individual']['lgb_wage']['test_mae'],
            self.results['ensemble']['wage']['test_mae']
        ]
        
        bars = axes[0, 1].bar(wage_models, wage_mae, color=colors)
        axes[0, 1].set_title('ì„ê¸ˆ ì˜ˆì¸¡ ëª¨ë¸ MAE ë¹„êµ', fontweight='bold', fontsize=12)
        axes[0, 1].set_ylabel('MAE (ë§Œì›)')
        
        for bar, value in zip(bars, wage_mae):
            height = bar.get_height()
            axes[0, 1].text(bar.get_x() + bar.get_width()/2., height + 1,
                           f'{value:.1f}', ha='center', va='bottom')
        
        # 3. ì„ê¸ˆ ì˜ˆì¸¡ RÂ² ë¹„êµ
        wage_r2 = [
            self.results['individual']['catboost_wage']['test_r2'],
            self.results['individual']['xgb_wage']['test_r2'],
            self.results['individual']['lgb_wage']['test_r2'],
            self.results['ensemble']['wage']['test_r2']
        ]
        
        bars = axes[0, 2].bar(wage_models, wage_r2, color=colors)
        axes[0, 2].set_title('ì„ê¸ˆ ì˜ˆì¸¡ ëª¨ë¸ RÂ² ë¹„êµ', fontweight='bold', fontsize=12)
        axes[0, 2].set_ylabel('RÂ² Score')
        
        for bar, value in zip(bars, wage_r2):
            height = bar.get_height()
            axes[0, 2].text(bar.get_x() + bar.get_width()/2., height + 0.01,
                           f'{value:.3f}', ha='center', va='bottom')
        
        # 4. ë§Œì¡±ë„ ì˜ˆì¸¡ ì •í™•ë„ ë¹„êµ
        sat_models = ['XGBoost', 'CatBoost', 'LightGBM', 'Ensemble']
        sat_acc = [
            self.results['individual']['xgb_satisfaction']['test_accuracy'],
            self.results['individual']['catboost_satisfaction']['test_accuracy'],
            self.results['individual']['lgb_satisfaction']['test_accuracy'],
            self.results['ensemble']['satisfaction']['test_accuracy']
        ]
        
        bars = axes[1, 0].bar(sat_models, sat_acc, color=colors)
        axes[1, 0].set_title('ë§Œì¡±ë„ ì˜ˆì¸¡ ëª¨ë¸ ì •í™•ë„ ë¹„êµ', fontweight='bold', fontsize=12)
        axes[1, 0].set_ylabel('Accuracy')
        
        for bar, value in zip(bars, sat_acc):
            height = bar.get_height()
            axes[1, 0].text(bar.get_x() + bar.get_width()/2., height + 0.005,
                           f'{value:.3f}', ha='center', va='bottom')
        
        # 5. ë² ì´ìŠ¤ë¼ì¸ ëŒ€ë¹„ ì„±ëŠ¥ (RMSE ì¤‘ì‹¬)
        baseline_models = ['ê¸°ì¡´\në² ì´ìŠ¤ë¼ì¸', 'ì „ì²´ ë°ì´í„°\nì•™ìƒë¸”']
        baseline_rmse = [115.92, self.results['ensemble']['wage']['test_rmse']]
        
        bars = axes[1, 1].bar(baseline_models, baseline_rmse, color=['lightgray', 'orange'])
        axes[1, 1].set_title('ì„ê¸ˆ ì˜ˆì¸¡ ë² ì´ìŠ¤ë¼ì¸ ëŒ€ë¹„ ì„±ëŠ¥', fontweight='bold', fontsize=12)
        axes[1, 1].set_ylabel('RMSE (ë§Œì›)')
        
        for bar, value in zip(bars, baseline_rmse):
            height = bar.get_height()
            axes[1, 1].text(bar.get_x() + bar.get_width()/2., height + 1,
                           f'{value:.1f}', ha='center', va='bottom')
        
        # 6. ì¢…í•© ì„±ëŠ¥ ìš”ì•½
        wage_result = self.results['ensemble']['wage']
        sat_result = self.results['ensemble']['satisfaction']
        
        summary_text = f'ğŸ¯ ì „ì²´ ë°ì´í„° ìµœì¢… ì„±ê³¼\n\n' + \
                      f'ğŸ’° ì„ê¸ˆ ì˜ˆì¸¡ ì•™ìƒë¸”\n' + \
                      f'   RMSE: {wage_result["test_rmse"]:.1f}ë§Œì›\n' + \
                      f'   MAE: {wage_result["test_mae"]:.1f}ë§Œì›\n' + \
                      f'   RÂ²: {wage_result["test_r2"]:.3f}\n\n' + \
                      f'ğŸ˜Š ë§Œì¡±ë„ ì˜ˆì¸¡ ì•™ìƒë¸”\n' + \
                      f'   ì •í™•ë„: {sat_result["test_accuracy"]:.3f}\n\n' + \
                      f'ğŸ“Š ë°ì´í„° ê·œëª¨\n' + \
                      f'   í›ˆë ¨: {len(self.X_train):,}ê°œ\n' + \
                      f'   í…ŒìŠ¤íŠ¸: {len(self.X_test):,}ê°œ'
        
        axes[1, 2].text(0.5, 0.5, summary_text, ha='center', va='center', fontsize=11,
                       bbox=dict(boxstyle="round,pad=0.5", facecolor="lightyellow"))
        axes[1, 2].set_xlim(0, 1)
        axes[1, 2].set_ylim(0, 1)
        axes[1, 2].set_title('ìµœì¢… ì„±ê³¼ ìš”ì•½', fontweight='bold', fontsize=12)
        axes[1, 2].axis('off')
        
        plt.tight_layout()
        plt.savefig('visualizations/full_dataset_final_comparison.png', dpi=300, bbox_inches='tight')
        plt.show()
    
    def save_final_models(self):
        """ìµœì¢… ëª¨ë¸ ì €ì¥"""
        print("\nìµœì¢… ëª¨ë¸ ì €ì¥ ì¤‘...")
        
        import os
        os.makedirs('models', exist_ok=True)
        os.makedirs('model_results', exist_ok=True)
        
        # ì•™ìƒë¸” ëª¨ë¸ ì €ì¥
        joblib.dump(self.ensemble_models['wage_ensemble'], 'models/full_dataset_wage_ensemble.pkl')
        joblib.dump(self.ensemble_models['satisfaction_ensemble'], 'models/full_dataset_satisfaction_ensemble.pkl')
        
        # ê°œë³„ ëª¨ë¸ë„ ì €ì¥
        for model_name, model in self.individual_models.items():
            joblib.dump(model, f'models/full_dataset_{model_name}.pkl')
        
        # ê²°ê³¼ ì €ì¥
        results_df = pd.DataFrame(self.results)
        results_df.to_csv('model_results/full_dataset_model_results.csv')
        
        print("  [ì™„ë£Œ] ì•™ìƒë¸” ëª¨ë¸ ì €ì¥ ì™„ë£Œ")
        print("  [ì™„ë£Œ] ê°œë³„ ëª¨ë¸ ì €ì¥ ì™„ë£Œ")
        print("  [ì™„ë£Œ] ì„±ëŠ¥ ê²°ê³¼ ì €ì¥ ì™„ë£Œ")
    
    def generate_comprehensive_report(self):
        """ì¢…í•© ì„±ëŠ¥ ë³´ê³ ì„œ - MAE í¬í•¨"""
        print("\n" + "="*80)
        print("ì „ì²´ ë°ì´í„°ì…‹ ê¸°ë°˜ ìµœì¢… ëª¨ë¸ ì„±ëŠ¥ ë³´ê³ ì„œ")
        print("="*80)
        
        print(f"\nğŸ“Š ë°ì´í„°ì…‹ ì •ë³´:")
        print(f"   í›ˆë ¨ ë°ì´í„°: {len(self.X_train):,}ê°œ")
        print(f"   í…ŒìŠ¤íŠ¸ ë°ì´í„°: {len(self.X_test):,}ê°œ")
        print(f"   íŠ¹ì„± ê°œìˆ˜: {len(self.feature_names)}ê°œ")
        print(f"   ì „ì²´ í™œìš©ë¥ : 100% (ì „ì²´ ë°ì´í„°ì…‹ ì‚¬ìš©)")
        
        print(f"\nğŸ’° ì„ê¸ˆ ì˜ˆì¸¡ ê²°ê³¼:")
        wage_result = self.results['ensemble']['wage']
        print(f"   ì•™ìƒë¸” ëª¨ë¸ ì„±ëŠ¥:")
        print(f"     - RMSE: {wage_result['test_rmse']:.2f}ë§Œì›")
        print(f"     - MAE: {wage_result['test_mae']:.2f}ë§Œì›")
        print(f"     - RÂ²: {wage_result['test_r2']:.4f}")
        
        # ìµœê³  ê°œë³„ ëª¨ë¸ê³¼ ë¹„êµ
        best_individual_wage = min(
            [(k, v) for k, v in self.results['individual'].items() if 'wage' in k], 
            key=lambda x: x[1]['test_rmse']
        )
        print(f"   ìµœê³  ê°œë³„ ëª¨ë¸: {best_individual_wage[0]}")
        print(f"     - RMSE: {best_individual_wage[1]['test_rmse']:.2f}ë§Œì›")
        print(f"     - MAE: {best_individual_wage[1]['test_mae']:.2f}ë§Œì›")
        
        rmse_improvement = best_individual_wage[1]['test_rmse'] - wage_result['test_rmse']
        mae_improvement = best_individual_wage[1]['test_mae'] - wage_result['test_mae']
        print(f"   ì•™ìƒë¸” ê°œì„ íš¨ê³¼:")
        print(f"     - RMSE: {rmse_improvement:+.2f}ë§Œì›")
        print(f"     - MAE: {mae_improvement:+.2f}ë§Œì›")
        
        print(f"\nğŸ˜Š ë§Œì¡±ë„ ì˜ˆì¸¡ ê²°ê³¼:")
        sat_result = self.results['ensemble']['satisfaction']
        print(f"   ì•™ìƒë¸” ëª¨ë¸ ì„±ëŠ¥:")
        print(f"     - ì •í™•ë„: {sat_result['test_accuracy']:.4f}")
        
        # ìµœê³  ê°œë³„ ëª¨ë¸ê³¼ ë¹„êµ
        best_individual_sat = max(
            [(k, v) for k, v in self.results['individual'].items() if 'satisfaction' in k],
            key=lambda x: x[1]['test_accuracy']
        )
        print(f"   ìµœê³  ê°œë³„ ëª¨ë¸: {best_individual_sat[0]}")
        print(f"     - ì •í™•ë„: {best_individual_sat[1]['test_accuracy']:.4f}")
        
        acc_improvement = sat_result['test_accuracy'] - best_individual_sat[1]['test_accuracy']
        print(f"   ì•™ìƒë¸” ê°œì„ íš¨ê³¼: {acc_improvement:+.4f}")
        
        # ê¸°ì¡´ ë² ì´ìŠ¤ë¼ì¸ ëŒ€ë¹„ ë¹„êµ
        print(f"\nğŸ”„ ê¸°ì¡´ ë² ì´ìŠ¤ë¼ì¸ ëŒ€ë¹„ ì„±ëŠ¥:")
        print(f"   ì„ê¸ˆ ì˜ˆì¸¡:")
        print(f"     - ê¸°ì¡´ ë² ì´ìŠ¤ë¼ì¸: 115.92ë§Œì› (RMSE)")
        print(f"     - ì „ì²´ ë°ì´í„° ì•™ìƒë¸”: {wage_result['test_rmse']:.2f}ë§Œì›")
        baseline_diff = 115.92 - wage_result['test_rmse']
        print(f"     - ê°œì„ íš¨ê³¼: {baseline_diff:+.2f}ë§Œì› ({'ğŸ‰ ê°œì„ ' if baseline_diff > 0 else 'âš ï¸ ì•…í™”'})")
        
        print(f"   ë§Œì¡±ë„ ì˜ˆì¸¡:")
        print(f"     - ê¸°ì¡´ ë² ì´ìŠ¤ë¼ì¸: 0.694 (ì •í™•ë„)")
        print(f"     - ì „ì²´ ë°ì´í„° ì•™ìƒë¸”: {sat_result['test_accuracy']:.4f}")
        baseline_diff_sat = sat_result['test_accuracy'] - 0.694
        print(f"     - ê°œì„ íš¨ê³¼: {baseline_diff_sat:+.4f} ({'ğŸ‰ ê°œì„ ' if baseline_diff_sat > 0 else 'âš ï¸ ì•…í™”'})")
        
        print(f"\nğŸ“ ìƒì„±ëœ ê²°ê³¼ë¬¼:")
        print(f"   - ì„ê¸ˆ ì˜ˆì¸¡ ì•™ìƒë¸”: models/full_dataset_wage_ensemble.pkl")
        print(f"   - ë§Œì¡±ë„ ì˜ˆì¸¡ ì•™ìƒë¸”: models/full_dataset_satisfaction_ensemble.pkl")
        print(f"   - ì„±ëŠ¥ ê²°ê³¼: model_results/full_dataset_model_results.csv")
        print(f"   - ì‹œê°í™”: visualizations/full_dataset_final_comparison.png")
        
        print(f"\nğŸš€ í”„ë¡œë•ì…˜ ì¤€ë¹„ ìƒíƒœ:")
        print(f"   âœ“ ì „ì²´ ë°ì´í„°ì…‹ìœ¼ë¡œ í›ˆë ¨ ì™„ë£Œ")
        print(f"   âœ“ MAE ì§€í‘œ í¬í•¨ ì¢…í•© í‰ê°€")
        print(f"   âœ“ ì•™ìƒë¸” ëª¨ë¸ ì„±ëŠ¥ ê²€ì¦")
        print(f"   âœ“ ëª¨ë¸ íŒŒì¼ ì €ì¥ ì™„ë£Œ")

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    start_time = time.time()
    
    print("ì „ì²´ ë°ì´í„°ì…‹ ê¸°ë°˜ ìµœì¢… ëª¨ë¸ êµ¬ì¶•ì„ ì‹œì‘í•©ë‹ˆë‹¤...")
    print("ì˜ˆìƒ ì†Œìš” ì‹œê°„: 15-30ë¶„ (ë°ì´í„° í¬ê¸°ì— ë”°ë¼)")
    
    # í•„ìš” í´ë” ìƒì„±
    import os
    os.makedirs('models', exist_ok=True)
    os.makedirs('model_results', exist_ok=True)
    os.makedirs('visualizations', exist_ok=True)
    
    # ì‹œìŠ¤í…œ ì´ˆê¸°í™”
    system = FullDatasetModelSystem()
    
    # ì‹¤í–‰
    system.load_and_prepare_data()
    system.train_individual_models()
    system.create_ensemble_models()
    system.evaluate_all_models()
    system.create_comprehensive_visualization()
    system.save_final_models()
    system.generate_comprehensive_report()
    
    total_time = (time.time() - start_time) / 60
    print(f"\nğŸ‰ ì „ì²´ ë¶„ì„ ì™„ë£Œ! ì´ ì†Œìš”ì‹œê°„: {total_time:.1f}ë¶„")
    print("="*80)

if __name__ == "__main__":
    main()