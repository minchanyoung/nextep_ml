import pandas as pd
import numpy as np
from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error
import catboost as cb
import matplotlib.pyplot as plt

print("=== í•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœì í™” ê²°ê³¼ ë¶„ì„ ===")

def load_data():
    """ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬"""
    df = pd.read_csv('processed_data/dataset_with_unified_occupations.csv')
    
    # ì˜ˆì¸¡ ê°€ëŠ¥í•œ ì¼€ì´ìŠ¤ë§Œ ì„ ë³„
    df_sorted = df.sort_values(['pid', 'year']).reset_index(drop=True)
    
    # ë‹¤ìŒ ì—°ë„ íƒ€ê²Ÿ ìƒì„±
    df_sorted['next_year'] = df_sorted.groupby('pid')['year'].shift(-1)
    df_sorted['next_wage'] = df_sorted.groupby('pid')['p_wage'].shift(-1)
    df_sorted['next_satisfaction'] = df_sorted.groupby('pid')['p4321'].shift(-1)
    
    # ì—°ì†ëœ ì—°ë„ë§Œ í•„í„°ë§
    consecutive_mask = (df_sorted['next_year'] == df_sorted['year'] + 1)
    df_consecutive = df_sorted[consecutive_mask].copy()
    
    # íƒ€ê²Ÿì´ ëª¨ë‘ ìˆëŠ” ì¼€ì´ìŠ¤ë§Œ ì„ ë³„
    valid_mask = (~df_consecutive['next_wage'].isna()) & (~df_consecutive['next_satisfaction'].isna())
    df_final = df_consecutive[valid_mask].copy()
    
    # ë§Œì¡±ë„ íƒ€ê²Ÿ ë³€ìˆ˜ì˜ ìœ íš¨í•œ ê°’(0 ì´ˆê³¼)ë§Œ í•„í„°ë§
    df_final = df_final[df_final['next_satisfaction'] > 0].copy()
    
    # íŠ¹ì„± ì„ íƒ
    exclude_cols = ['pid', 'year', 'next_year', 'next_wage', 'next_satisfaction', 'p_wage', 'p4321']
    feature_cols = [col for col in df_final.columns if col not in exclude_cols]
    
    # ë²”ì£¼í˜• ë³€ìˆ˜ ì¸ì½”ë”©
    from sklearn.preprocessing import LabelEncoder
    for col in df_final[feature_cols].select_dtypes(include=['object']).columns:
        le = LabelEncoder()
        df_final[col] = le.fit_transform(df_final[col].astype(str))
    
    # ê²°ì¸¡ê°’ ì²˜ë¦¬
    df_final[feature_cols] = df_final[feature_cols].fillna(df_final[feature_cols].median())
    
    # ì‹œê°„ ê¸°ë°˜ ë¶„í• 
    train_mask = df_final['year'] <= 2020
    test_mask = df_final['year'] >= 2021
    
    X_train = df_final[train_mask][feature_cols]
    X_test = df_final[test_mask][feature_cols]
    y_wage_train = df_final[train_mask]['next_wage']
    y_wage_test = df_final[test_mask]['next_wage']
    
    return X_train, X_test, y_wage_train, y_wage_test

def test_optimized_parameters():
    """ìµœì í™”ëœ íŒŒë¼ë¯¸í„°ë¡œ ëª¨ë¸ í…ŒìŠ¤íŠ¸"""
    X_train, X_test, y_wage_train, y_wage_test = load_data()
    
    # ìµœì í™”ëœ íŒŒë¼ë¯¸í„° (Trial 15 ê²°ê³¼)
    optimized_params = {
        'iterations': 860,
        'learning_rate': 0.010426694594004318,
        'depth': 8,
        'l2_leaf_reg': 8.653255320409505,
        'border_count': 216,
        'random_seed': 42,
        'verbose': False
    }
    
    # ê¸°ì¡´ ë² ì´ìŠ¤ë¼ì¸ íŒŒë¼ë¯¸í„°
    baseline_params = {
        'iterations': 1000,
        'learning_rate': 0.1,
        'depth': 6,
        'random_seed': 42,
        'verbose': False
    }
    
    print("ëª¨ë¸ í›ˆë ¨ ë° ë¹„êµ ì¤‘...")
    
    # ìµœì í™”ëœ ëª¨ë¸
    optimized_model = cb.CatBoostRegressor(**optimized_params)
    optimized_model.fit(X_train, y_wage_train)
    
    # ë² ì´ìŠ¤ë¼ì¸ ëª¨ë¸
    baseline_model = cb.CatBoostRegressor(**baseline_params)
    baseline_model.fit(X_train, y_wage_train)
    
    # ì˜ˆì¸¡
    opt_pred_train = optimized_model.predict(X_train)
    opt_pred_test = optimized_model.predict(X_test)
    
    base_pred_train = baseline_model.predict(X_train)
    base_pred_test = baseline_model.predict(X_test)
    
    # ì„±ëŠ¥ ê³„ì‚°
    results = {
        'optimized': {
            'train_rmse': np.sqrt(mean_squared_error(y_wage_train, opt_pred_train)),
            'test_rmse': np.sqrt(mean_squared_error(y_wage_test, opt_pred_test)),
            'train_r2': r2_score(y_wage_train, opt_pred_train),
            'test_r2': r2_score(y_wage_test, opt_pred_test),
            'train_mae': mean_absolute_error(y_wage_train, opt_pred_train),
            'test_mae': mean_absolute_error(y_wage_test, opt_pred_test)
        },
        'baseline': {
            'train_rmse': np.sqrt(mean_squared_error(y_wage_train, base_pred_train)),
            'test_rmse': np.sqrt(mean_squared_error(y_wage_test, base_pred_test)),
            'train_r2': r2_score(y_wage_train, base_pred_train),
            'test_r2': r2_score(y_wage_test, base_pred_test),
            'train_mae': mean_absolute_error(y_wage_train, base_pred_train),
            'test_mae': mean_absolute_error(y_wage_test, base_pred_test)
        }
    }
    
    return results, optimized_model, baseline_model

def print_results(results):
    """ê²°ê³¼ ì¶œë ¥"""
    print("\n=== í•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœì í™” ì„±ëŠ¥ ë¹„êµ ===\n")
    
    print("ğŸ“Š **ì„ê¸ˆ ì˜ˆì¸¡ ëª¨ë¸ ì„±ëŠ¥ ë¹„êµ**")
    print("=" * 50)
    
    opt = results['optimized']
    base = results['baseline']
    
    print(f"ğŸ”¹ **ìµœì í™”ëœ ëª¨ë¸**")
    print(f"   - í…ŒìŠ¤íŠ¸ RMSE: {opt['test_rmse']:.2f}ë§Œì›")
    print(f"   - í…ŒìŠ¤íŠ¸ MAE: {opt['test_mae']:.2f}ë§Œì›")
    print(f"   - í…ŒìŠ¤íŠ¸ RÂ²: {opt['test_r2']:.4f}")
    print()
    
    print(f"ğŸ”¸ **ê¸°ì¡´ ë² ì´ìŠ¤ë¼ì¸**")
    print(f"   - í…ŒìŠ¤íŠ¸ RMSE: {base['test_rmse']:.2f}ë§Œì›")
    print(f"   - í…ŒìŠ¤íŠ¸ MAE: {base['test_mae']:.2f}ë§Œì›")
    print(f"   - í…ŒìŠ¤íŠ¸ RÂ²: {base['test_r2']:.4f}")
    print()
    
    # ê°œì„ ìœ¨ ê³„ì‚°
    rmse_improvement = ((base['test_rmse'] - opt['test_rmse']) / base['test_rmse']) * 100
    mae_improvement = ((base['test_mae'] - opt['test_mae']) / base['test_mae']) * 100
    r2_improvement = ((opt['test_r2'] - base['test_r2']) / base['test_r2']) * 100
    
    print(f"ğŸ“ˆ **ì„±ëŠ¥ ê°œì„ **")
    print(f"   - RMSE ê°œì„ : {rmse_improvement:.1f}% (ë” ë‚®ì„ìˆ˜ë¡ ì¢‹ìŒ)")
    print(f"   - MAE ê°œì„ : {mae_improvement:.1f}% (ë” ë‚®ì„ìˆ˜ë¡ ì¢‹ìŒ)")
    print(f"   - RÂ² ê°œì„ : {r2_improvement:.1f}% (ë” ë†’ì„ìˆ˜ë¡ ì¢‹ìŒ)")
    
    return {
        'rmse_improvement': rmse_improvement,
        'mae_improvement': mae_improvement,
        'r2_improvement': r2_improvement
    }

def save_results(results, improvements):
    """ê²°ê³¼ ì €ì¥"""
    # CSV ì €ì¥
    results_df = pd.DataFrame(results).T
    results_df.to_csv('model_results/hyperparameter_optimization_comparison.csv')
    
    # ê°œì„ ìœ¨ ì €ì¥
    improvements_df = pd.DataFrame([improvements])
    improvements_df.to_csv('model_results/optimization_improvements.csv', index=False)
    
    print(f"\nğŸ’¾ ê²°ê³¼ ì €ì¥ ì™„ë£Œ")
    print(f"   - model_results/hyperparameter_optimization_comparison.csv")
    print(f"   - model_results/optimization_improvements.csv")

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("í•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœì í™” ê²°ê³¼ ë¶„ì„ ì‹œì‘...")
    
    # ëª¨ë¸ ë¹„êµ
    results, opt_model, base_model = test_optimized_parameters()
    
    # ê²°ê³¼ ì¶œë ¥
    improvements = print_results(results)
    
    # ê²°ê³¼ ì €ì¥
    save_results(results, improvements)
    
    # ëª¨ë¸ ì €ì¥
    import joblib
    joblib.dump(opt_model, 'models/optimized_catboost_wage.pkl')
    joblib.dump(base_model, 'models/baseline_catboost_wage.pkl')
    
    print(f"\nğŸ¯ **ìµœì¢… ê²°ë¡ **")
    if improvements['rmse_improvement'] > 0:
        print(f"   âœ… í•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœì í™”ê°€ ì„±ê³µì ìœ¼ë¡œ ëª¨ë¸ ì„±ëŠ¥ì„ ê°œì„ í–ˆìŠµë‹ˆë‹¤!")
        print(f"   ğŸ“ˆ RMSE {improvements['rmse_improvement']:.1f}% ê°œì„ ìœ¼ë¡œ ì˜ˆì¸¡ ì •í™•ë„ê°€ í–¥ìƒë˜ì—ˆìŠµë‹ˆë‹¤.")
    else:
        print(f"   âš ï¸ ìµœì í™” ê²°ê³¼ê°€ ë² ì´ìŠ¤ë¼ì¸ê³¼ ìœ ì‚¬í•˜ê±°ë‚˜ ì•½ê°„ ë‚®ìŠµë‹ˆë‹¤.")
        print(f"   ğŸ” ì¶”ê°€ì ì¸ íŠ¹ì„± ì—”ì§€ë‹ˆì–´ë§ì´ë‚˜ ë‹¤ë¥¸ ì ‘ê·¼ì´ í•„ìš”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")

if __name__ == "__main__":
    main()