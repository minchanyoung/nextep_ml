# 머신러닝 프로젝트 진행 상황 최종 요약

**업데이트 일시**: 2025-09-14
**프로젝트**: 한국노동패널조사(KLIPS) 데이터 기반 임금 및 직업만족도 예측

---

## 📋 프로젝트 최종 성과 요약

이 프로젝트는 초기 베이스라인 모델부터 시작하여, 앙상블 기법(Voting, Stacking)을 거쳐 최종적으로 시계열 데이터의 특성을 활용하는 LSTM 모델에 이르기까지 체계적인 성능 개선 과정을 거쳤습니다. 각 단계별 핵심 성과는 다음과 같습니다.

### 💰 임금 예측 모델 성능 (회귀 문제)

*주요 지표: RMSE (Root Mean Squared Error), MAE (Mean Absolute Error), R² (R-squared)*

| 모델 유형 | 모델명 | RMSE (만원) | MAE (만원) | R² | 비고 |
| :--- | :--- | :--- | :--- | :--- | :--- |
| **초기 베이스라인** | CatBoost | 115.92 | - | - | 프로젝트 초기 기준 |
| **개별 모델** | CatBoost | 117.36 | 57.58 | 0.6858 | |
| | XGBoost | 134.87 | 62.16 | 0.5851 | |
| | LightGBM | 119.92 | 60.44 | 0.6720 | |
| **앙상블 모델** | Voting 앙상블 | 118.89 | 58.35 | 0.6776 | |
| **최적화 개별 모델** | CatBoost (최적화) | 116.76 | 57.92 | 0.6890 | 하이퍼파라미터 최적화 후 |
| | XGBoost | 124.75 | 60.61 | 0.6450 | |
| | LightGBM | 119.16 | 59.72 | 0.6761 | |
| **최적화 앙상블** | Voting 앙상블 | 116.42 | 57.85 | 0.6908 | 최적화된 개별 모델로 재구성 |
| **LSTM 모델** | 초기 LSTM | 107.54 | - | - | 시계열 데이터 학습 |
| | **Optimized LSTM** | **97.95** | **65.60** | **0.7408** | **임금 예측 최종 최고 성능** |

### 😊 직업 만족도 예측 모델 성능 (분류 문제)

*주요 지표: 정확도 (Accuracy), F1-score*

| 모델 유형 | 모델명 | 정확도 (Accuracy) | F1-score | 비고 |
| :--- | :--- | :--- | :--- | :--- |
| **초기 베이스라인** | XGBoost | 0.6940 | - | 프로젝트 초기 기준 |
| **개별 모델** | XGBoost | 0.6658 | - | |
| | CatBoost | 0.6750 | - | |
| | LightGBM | 0.6690 | - | |
| **앙상블 모델** | **Voting 앙상블** | **0.6716** | **0.6545** | |
| **최적화 개별 모델** | XGBoost (최적화) | 0.6744 | 0.6526 | 하이퍼파라미터 최적화 후 |
| | CatBoost | 0.6752 | 0.6539 | |
| | LightGBM | 0.6728 | 0.6534 | |
| **최적화 앙상블** | **Voting 앙상블** | **0.6753** | **0.6545** | **만족도 예측 최종 최고 성능** |
| **LSTM 모델** | 초기 LSTM | 0.6182 | - | 시계열 데이터 학습 |
| | Optimized LSTM | 0.6103 | - | |

### 🎯 최종 결론
- **임금(Wage) 예측**: **최적화된 LSTM 모델**이 시계열 패턴을 효과적으로 학습하여, 기존의 모든 모델을 뛰어넘는 **가장 높은 예측 정확도(RMSE 97.95)**를 달성했습니다.
- **만족도(Satisfaction) 예측**: 여러 시도에도 불구하고, 초기 **Voting 앙상블 모델**이 **가장 안정적이고 높은 예측 정확도(0.6753)**를 유지했습니다.

**따라서, 각 타겟에 가장 우수한 성능을 보이는 모델을 조합하여 사용하는 '하이브리드(Hybrid)' 접근 방식이 최적의 전략으로 판단됩니다.**

---

### 😊 만족도 모델 클래스 불균형 개선 심화 실험

만족도 예측 모델의 성능을 추가적으로 개선하기 위해, 기존에 시도했던 `Class Weight` 및 `SMOTE` 기법 외에 `Focal Loss`를 추가로 실험하여 비교 분석했습니다.

| 처리 기법 | 모델 | 정확도 (Accuracy) | F1-Score (Weighted) | 비고 |
| :--- | :--- | :--- | :--- | :--- |
| **Baseline** | XGBoost | 0.6724 | 0.6507 | 처리 안함 |
| **Class Weight** | XGBoost | 0.6302 | 0.6390 | 소수 클래스 재현율 상승, 전반적 성능 하락 |
| **SMOTE** | XGBoost | **0.6734** | **0.6540** | **가장 높은 F1-Score 달성** |
| **Focal Loss** | CatBoost | 0.6280 | 0.6377 | Class Weight와 유사한 경향 |

#### 실험 결론
- **SMOTE의 우수성 재확인**: 여러 기법 중 **SMOTE**가 전반적인 F1-Score(`0.6540`)를 가장 효과적으로 향상시키는 것으로 다시 한번 확인되었습니다.
- **Focal Loss/Class Weight의 한계**: `Focal Loss`와 `Class Weight`는 소수 클래스의 재현율(Recall)을 높이는 데는 기여했지만, 이로 인해 다른 클래스의 정밀도(Precision)가 낮아져 전체적인 F1-Score는 오히려 감소했습니다.
- **최종 모델 유지**: 따라서 만족도 예측 모델은 여전히 **SMOTE**로 처리된 데이터로 학습하는 것이 최적의 전략으로 판단됩니다.

---

## 🚀 최종 제안: 하이브리드 모델 기반 서비스 구축

각기 다른 모델이 두 개의 타겟 변수(임금, 만족도)에 대해 최고의 성능을 보이므로, 다음과 같이 두 모델의 장점을 결합한 최종 서비스를 구축할 것을 제안합니다.

### 모델 선택 이유

1.  **임금 예측 → Optimized LSTM 모델**
    - **선택 이유**: 임금은 개인의 경력, 연차 등에 따라 **강한 시계열 경향성**을 보입니다. LSTM 모델은 이러한 순차적인 데이터 패턴을 학습하는 데 특화되어 있어, 기존의 정적(static)인 트리 기반 앙상블 모델보다 훨씬 뛰어난 예측 성능을 달성했습니다.

2.  **직업 만족도 예측 → Voting 앙상블 모델**
    - **선택 이유**: 직업 만족도는 임금과 달리 뚜렷한 시계열 경향성을 보이지 않았습니다. 오히려 특정 시점의 복합적인 요인(업무 환경, 대인 관계, 개인 스트레스 등)에 더 큰 영향을 받는 **주관적이고 변동성 높은 데이터**입니다. 트리 기반의 Voting 앙상블 모델은 이러한 비선형적이고 복잡한 상호작용을 포착하는 데 더 강점을 보여 가장 안정적이고 높은 정확도를 기록했습니다.

### 최종 모델 구성

- **임금 예측 모델**: `best_lstm_model_optimized.keras`
- **직업 만족도 예측 모델**: `optimized_satisfaction_voting_ensemble.pkl`

### 기대 효과
- 각 예측 목표에 대해 현재까지 검증된 **최고의 성능**을 사용자에게 제공할 수 있습니다.
- 단일 모델의 한계를 극복하고, 프로젝트 과정에서 확보된 모든 자산(모델)을 효과적으로 활용할 수 있습니다.

---

## 💡 다음 단계 (Next Steps)

1.  **하이브리드 예측 서비스 스크립트 개발**:
    - 두 개의 다른 모델(LSTM, Voting Ensemble)을 로드하여, 단일 사용자 입력에 대해 임금과 만족도를 각각 예측하고 결과를 통합하여 반환하는 `hybrid_prediction_service.py` 스크립트를 개발합니다.

2.  **최종 모델 통합 및 API 엔드포인트 구현**:
    - 기존에 구현된 `user_occupation_service.py`를 수정하거나 확장하여, 하이브리드 모델을 기반으로 실제 예측을 수행하는 API 엔드포인트를 완성합니다.

3.  **프로젝트 최종 보고서 작성**:
    - 데이터 전처리부터 최종 모델 선정까지의 전 과정을 정리한 `FINAL_PROJECT_REPORT.md` 문서를 작성하여 프로젝트의 성과와 결론을 공식화합니다.

4.  **코드 리팩토링 및 정리**:
    - 최종적으로 사용될 스크립트와 모델 중심으로 프로젝트 폴더 구조를 정리하고, 불필요한 실험 코드를 `archives` 폴더 등으로 이동시켜 코드의 가독성과 유지보수성을 높입니다.
