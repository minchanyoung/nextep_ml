# LSTM 모델 실험 보고서

**보고서 생성일**: 2025-09-13

## 1. 실험 개요

- **목표**: 기존에 구축된 머신러닝 모델(Voting 앙상블)의 성능을 뛰어넘기 위해, 데이터의 시계열적 특성을 학습할 수 있는 LSTM(Long Short-Term Memory) 모델을 적용합니다.
- **핵심 아이디어**: 개인의 과거 5년간 데이터를 하나의 시퀀스로 보고, 다음 연도의 임금과 직업 만족도를 동시에 예측하여 시간의 흐름에 따른 패턴을 모델이 직접 학습하도록 합니다.

---

## 2. 실행 과정

1.  **데이터 전처리 (`01_create_sequences.py`)**: 
    - 원본 데이터셋(`ml_dataset_engineered.csv`)을 LSTM 모델에 입력할 수 있는 시퀀스 형태로 가공했습니다.
    - 총 **81,228개**의 시퀀스가 생성되었으며, 이 중 69,153개는 훈련용, 12,075개는 테스트용으로 분리되었습니다.
    - 데이터는 `lstm/data/` 폴더에 저장되었습니다.

2.  **모델 훈련 (`02_train_lstm.py`)**:
    - 2개의 LSTM 레이어를 기반으로 임금(회귀)과 만족도(분류)를 예측하는 Multi-output 모델을 구축했습니다.
    - 총 22 Epoch 동안 훈련이 진행되었으며, `EarlyStopping` 콜백에 의해 최적의 성능을 보인 17 Epoch 시점의 모델이 최종 선택되었습니다.
    - 훈련된 모델은 `lstm/models/best_lstm_model.keras`에 저장되었습니다.

---

## 3. 최종 평가 결과

LSTM 모델과 기존 Voting 앙상블 모델의 성능을 동일한 테스트 데이터셋 기준으로 비교한 결과입니다.

| 모델 | 임금 예측 RMSE (만원) | 만족도 예측 정확도 |
| :--- | :--- | :--- |
| 기존 Voting 앙상블 | 116.42 | **0.6753** |
| **LSTM 모델 (신규)** | **107.54** | 0.6182 |

*참고: 임금 RMSE는 낮을수록, 만족도 정확도는 높을수록 우수합니다.*

---

## 4. 결론 및 분석

### 성과
- **임금 예측 성능 대폭 향상**: LSTM 모델은 기존 Voting 앙상블 모델 대비 **RMSE를 약 8.9만 원 (7.6%) 개선**시켰습니다. 이는 LSTM이 개인의 시간에 따른 임금 변화 패턴을 성공적으로 학습했음을 의미합니다.
- **시계열 특성 학습 가능성 확인**: 별도의 복잡한 시계열 특성 엔지니어링 없이도, LSTM 모델이 데이터의 순차적 특성에서 유의미한 정보를 추출할 수 있음을 증명했습니다.

### 한계점 및 개선 방향
- **만족도 예측 성능 하락**: 만족도 예측의 경우, 정확도가 기존 모델보다 낮게 나왔습니다. 이는 만족도라는 주관적 지표가 임금처럼 뚜렷한 시계열 패턴을 갖지 않거나, 현재 모델 구조가 분류 문제에 최적화되지 않았을 수 있음을 시사합니다.
- **개선 방향**:
    1.  **하이퍼파라미터 튜닝**: LSTM 레이어의 유닛 수, Dropout 비율, 학습률 등을 Optuna를 사용해 최적화하여 성능을 추가로 개선할 수 있습니다.
    2.  **아키텍처 변경**: GRU(Gated Recurrent Unit) 모델을 시도하거나, Attention 메커니즘을 추가하여 특정 시점의 데이터에 더 집중하도록 모델을 개선할 수 있습니다.
    3.  **손실 함수 가중치 조정**: 만족도 예측의 손실 가중치를 높여, 모델이 만족도 예측에 더 집중하도록 유도해볼 수 있습니다.

**종합적으로, LSTM은 임금 예측에 있어 매우 유망한 접근법임을 확인했으며, 추가적인 튜닝을 통해 더 높은 성능을 기대할 수 있습니다.**
